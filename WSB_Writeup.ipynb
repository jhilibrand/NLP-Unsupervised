{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c41fd8-4851-48a2-8d6b-77a2a160394b",
   "metadata": {},
   "source": [
    "# WSB Topic Modeling Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e46922-5af6-4ba3-ace9-3a062e59273f",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "The goal of this project was to build a topic map of the discussions on WallStreetBets, a popular subreddit, during the first half of this year. The aim being to have a clearer picture of what topics were being discussed during the outlier price movement of GME, AMC, and other \"meme\" stocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d9fab9-d1c5-4c22-82ad-c393ed724003",
   "metadata": {},
   "source": [
    "## Design and Data \n",
    "\n",
    "In order to get a sample that represented how the WallStreetBets subreddit evolved over time, I scrapped the top 100 posts, per month, from January through June. This avoids bias towards the peak of the subreddit's popularity (late Jan-February). This collection of the top 100 posts, which includes all comments, totalled ~60k comments, ~1.4m words, and ~40k unique words. \n",
    "\n",
    "Once this data was scrapped, I built a topic model (discussed below in Algorithms). The below graph shows how these topics evolved (in strenght) over time, overlayed with GME stock movements.\n",
    "\n",
    "\n",
    " ![title](Topic_Strength_v_GME.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6c274-81d2-492b-b4f8-479bdb8e3775",
   "metadata": {},
   "source": [
    "## Algorithms \n",
    "\n",
    "Once this data was scrapped, I used LSA and NMF to build a topic model (two models that work well with short form/social media style posts). After assessing the results, my NMF model made the clearest categories amongst the text data, and my analysis continued on the NMF model. The below is the name I assigned to each topic my model generated, and the top 25 words associated with that topic.\n",
    "\n",
    "**\"Anti-Establishment, Censorship, Conspiracy\"**\n",
    "* fraud, robinhood, sec, server, discord, media, social, important, posts, bloomberg, markets, hunts, drove, articles, integrity, gamestop, wallstreet, financial, news, securities, wallstreetbets, hateful, warnings, evidence, jail\n",
    "\n",
    "**\"GME, AMC, Fanaticism\"**\n",
    "* gme, like, just, stock, people, shares, don, buy, price, going, money, make, market, think, short, sell, want, buying, fucking, know, ve, funds, fuck, time, hedge, holding\n",
    "\n",
    "**\"Hype, Teamwork, Enthusiasm\"**\n",
    "* amc, bb, buy, nok, moon, bought, today, holding, tomorrow, stocks, let, movies, nbsp, hedge, security, got, wish, time, br, shares, war, trading, clov, low, market\n",
    "\n",
    "**\"US v Hedge Funds, Underdogs, Squeeze the Shorts\"**\n",
    "* cover, days, short, friday, sell, melvin, day, capital, shorts, shares, fucking, squeeze, covering, week, ass, dildos, gonna, ratio, volume, need, million, shorted, number, position, starts\n",
    "\n",
    "**\"Holding\"**\n",
    "* gme, hold, buy, bb, holding, moon, rkt, fucking, squeeze, nbsp, nok, today, line, let, silver, stocks, apes, financial, tomorrow, fuck, hands, wsb, edit, account, strong\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bde1025-e5b7-463a-b1fa-d124a573c5b4",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "* Praw, PushShift for scrapping\n",
    "* Pandas, Numpy for EDA\n",
    "* SKlearn and NLTK for modeling\n",
    "* Tableau and Streamlit for visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0183ca50-fe6f-40fb-9af1-ce98844076ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
